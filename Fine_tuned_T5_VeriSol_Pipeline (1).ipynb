{"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\nfor root, dirs, files in os.walk('/work'):\n    for f in files:\n        os.unlink(os.path.join(root, f))\n    for d in dirs:\n        shutil.rmtree(os.path.join(root, d))","metadata":{"tags":[],"cell_id":"a9fc05731ffe4bce9f3381a22b801955","source_hash":"9bd4ae78","execution_start":1677443718919,"execution_millis":18126,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install sentencepiece\n!pip install transformers\n!pip install rich[jupyter]\n!pip install anvil-uplink\n!pip install --upgrade pip\n!pip3 install --upgrade protobuf==3.20.0","metadata":{"id":"BudqzauWKAzE","colab":{"height":1000,"base_uri":"https://localhost:8080/"},"cell_id":"bf83eabab0af41429c4188ac20250bfa","outputId":"b9cb67d4-019e-493a-fd83-32eeeacf33ae","source_hash":"c8dda7c3","execution_start":1677443737095,"execution_millis":16630,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /root/venv/lib/python3.7/site-packages (0.1.97)\nRequirement already satisfied: transformers in /root/venv/lib/python3.7/site-packages (4.26.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/venv/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers) (5.0.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /root/venv/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: requests in /root/venv/lib/python3.7/site-packages (from transformers) (2.21.0)\nRequirement already satisfied: tqdm>=4.27 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: numpy>=1.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: regex!=2019.12.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers) (2022.9.13)\nRequirement already satisfied: filelock in /shared-libs/python3.7/py/lib/python3.7/site-packages (from transformers) (3.8.0)\nRequirement already satisfied: pyyaml>=5.1 in /root/venv/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.9.0)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /root/venv/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nCollecting idna<2.9,>=2.5\n  Using cached idna-2.8-py2.py3-none-any.whl (58 kB)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /root/venv/lib/python3.7/site-packages (from requests->transformers) (1.24.3)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nInstalling collected packages: idna\n  Attempting uninstall: idna\n    Found existing installation: idna 3.4\n    Not uninstalling idna at /shared-libs/python3.7/py-core/lib/python3.7/site-packages, outside environment /root/venv\n    Can't uninstall 'idna'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-colab 1.0.0 requires ipykernel~=4.6.0, but you have ipykernel 6.16.1 which is incompatible.\ngoogle-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook~=5.2.0, but you have notebook 6.5.1 which is incompatible.\ngoogle-colab 1.0.0 requires six~=1.12.0, but you have six 1.16.0 which is incompatible.\ngoogle-colab 1.0.0 requires tornado~=4.5.0, but you have tornado 6.2 which is incompatible.\ntensorboard 2.10.1 requires google-auth<3,>=1.6.3, but you have google-auth 1.4.2 which is incompatible.\ntensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\nspacy 3.4.2 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\nsnowflake-connector-python 2.7.9 requires charset-normalizer~=2.0.0, but you have charset-normalizer 2.1.1 which is incompatible.\ngoogle-cloud-bigquery 3.3.5 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\ngoogle-api-core 2.10.2 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.4.2 which is incompatible.\ngoogle-api-core 2.10.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed idna-2.8\nRequirement already satisfied: rich[jupyter] in /root/venv/lib/python3.7/site-packages (13.3.1)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /root/venv/lib/python3.7/site-packages (from rich[jupyter]) (2.2.0)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from rich[jupyter]) (4.4.0)\nCollecting pygments<3.0.0,>=2.14.0\n  Using cached Pygments-2.14.0-py3-none-any.whl (1.1 MB)\nRequirement already satisfied: ipywidgets<9,>=7.5.1 in /root/venv/lib/python3.7/site-packages (from rich[jupyter]) (8.0.4)\nRequirement already satisfied: ipython>=6.1.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (5.5.0)\nRequirement already satisfied: ipykernel>=4.5.1 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (6.16.1)\nRequirement already satisfied: jupyterlab-widgets~=3.0 in /root/venv/lib/python3.7/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (3.0.5)\nRequirement already satisfied: widgetsnbextension~=4.0 in /root/venv/lib/python3.7/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (4.0.5)\nRequirement already satisfied: mdurl~=0.1 in /root/venv/lib/python3.7/site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich[jupyter]) (0.1.2)\nRequirement already satisfied: nest-asyncio in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.5.6)\nRequirement already satisfied: tornado>=6.1 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.2)\nRequirement already satisfied: psutil in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (5.9.3)\nRequirement already satisfied: matplotlib-inline>=0.1 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.1.6)\nRequirement already satisfied: packaging in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (21.3)\nRequirement already satisfied: jupyter-client>=6.1.12 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (7.4.3)\nRequirement already satisfied: debugpy>=1.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.6.3)\nRequirement already satisfied: pyzmq>=17 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (24.0.1)\nRequirement already satisfied: decorator in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (5.1.1)\nRequirement already satisfied: pickleshare in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.5)\nRequirement already satisfied: backcall in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.8.0)\nRequirement already satisfied: jedi>=0.16 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.17.2)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.0.31)\nRequirement already satisfied: setuptools>=18.5 in /root/venv/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (47.1.0)\nRequirement already satisfied: parso<0.8.0,>=0.7.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.8.2)\nRequirement already satisfied: entrypoints in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.4)\nRequirement already satisfied: jupyter-core>=4.9.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.11.2)\nRequirement already satisfied: ptyprocess>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.0)\nRequirement already satisfied: wcwidth in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.0.9)\nRequirement already satisfied: six>=1.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.16.0)\nInstalling collected packages: pygments\n  Attempting uninstall: pygments\n    Found existing installation: Pygments 2.13.0\n    Not uninstalling pygments at /shared-libs/python3.7/py-core/lib/python3.7/site-packages, outside environment /root/venv\n    Can't uninstall 'Pygments'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-colab 1.0.0 requires ipykernel~=4.6.0, but you have ipykernel 6.16.1 which is incompatible.\ngoogle-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook~=5.2.0, but you have notebook 6.5.1 which is incompatible.\ngoogle-colab 1.0.0 requires six~=1.12.0, but you have six 1.16.0 which is incompatible.\ngoogle-colab 1.0.0 requires tornado~=4.5.0, but you have tornado 6.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pygments-2.14.0\nRequirement already satisfied: anvil-uplink in /root/venv/lib/python3.7/site-packages (0.4.2)\nRequirement already satisfied: ws4py in /root/venv/lib/python3.7/site-packages (from anvil-uplink) (0.5.1)\nCollecting argparse\n  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: future in /shared-libs/python3.7/py/lib/python3.7/site-packages (from anvil-uplink) (0.18.2)\nRequirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from anvil-uplink) (1.16.0)\nInstalling collected packages: argparse\nSuccessfully installed argparse-1.4.0\nRequirement already satisfied: pip in /root/venv/lib/python3.7/site-packages (23.0.1)\nRequirement already satisfied: protobuf==3.20.0 in /root/venv/lib/python3.7/site-packages (3.20.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!wget -q http://ftp.de.debian.org/debian/pool/main/i/icu/libicu63_63.1-6+deb10u3_amd64.deb\n!dpkg -i /work/libicu63_63.1-6+deb10u3_amd64.deb\n!sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys EB3E94ADBE1229CF \n!wget -q https://dotnet.microsoft.com/download/dotnet/scripts/v1/dotnet-install.ps1\n!wget -q https://packages.microsoft.com/config/ubuntu/18.04/prod.list\n!sudo mv prod.list /etc/apt/sources.list.d/microsoft-prod.list\n!sudo apt update\n!sudo apt-get install libicu63","metadata":{"id":"UNG_acOmI_9w","colab":{"base_uri":"https://localhost:8080/"},"cell_id":"92a7cb2203b941a1a828ed256ffdb0af","outputId":"b20f1dfe-300b-4aba-f397-834a8e55bc10","source_hash":"ffe6c80d","execution_start":1677443753738,"execution_millis":6700,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"(Reading database ... 33281 files and directories currently installed.)\nPreparing to unpack .../libicu63_63.1-6+deb10u3_amd64.deb ...\nUnpacking libicu63:amd64 (63.1-6+deb10u3) over (63.1-6+deb10u3) ...\nSetting up libicu63:amd64 (63.1-6+deb10u3) ...\nProcessing triggers for libc-bin (2.28-10+deb10u2) ...\nExecuting: /tmp/apt-key-gpghome.bDpsA8yo0i/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys EB3E94ADBE1229CF\ngpg: key EB3E94ADBE1229CF: \"Microsoft (Release signing) <gpgsecurity@microsoft.com>\" not changed\ngpg: Total number processed: 1\ngpg:              unchanged: 1\nHit:1 http://deb.debian.org/debian buster InRelease\nGet:2 http://deb.debian.org/debian-security buster/updates InRelease [34.8 kB]\nGet:3 http://deb.debian.org/debian buster-updates InRelease [56.6 kB]\nHit:4 https://packages.microsoft.com/ubuntu/18.04/prod bionic InRelease\nFetched 91.5 kB in 0s (262 kB/s)\n\n\n\n9 packages can be upgraded. Run 'apt list --upgradable' to see them.\n\n\n\nlibicu63 is already the newest version (63.1-6+deb10u3).\n0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!sudo apt-get install aspnetcore-runtime-2.2 -y \n!sudo apt-get install dotnet-sdk-2.2 -y\n!git clone https://github.com/microsoft/verisol.git\n!cd /work/verisol/Sources\n!dotnet build /work/verisol/Sources","metadata":{"id":"9LIIAYRqaWCF","colab":{"base_uri":"https://localhost:8080/"},"cell_id":"59ac4405559e4f83951d5872731ff79b","outputId":"cc2cf2ec-4247-4c34-9511-754293dc9434","source_hash":"2b2159c1","execution_start":1677443760479,"execution_millis":11376,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"\n\n\naspnetcore-runtime-2.2 is already the newest version (2.2.8-1).\n0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n\n\n\ndotnet-sdk-2.2 is already the newest version (2.2.402-1).\n0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\nCloning into 'verisol'...\nremote: Enumerating objects: 5429, done.\u001b[K\nremote: Counting objects: 100% (153/153), done.\u001b[K\nremote: Compressing objects: 100% (110/110), done.\u001b[K\nremote: Total 5429 (delta 37), reused 113 (delta 27), pack-reused 5276\u001b[K\nReceiving objects: 100% (5429/5429), 3.46 MiB | 39.34 MiB/s, done.\nResolving deltas: 100% (3802/3802), done.\nChecking out files: 100% (584/584), done.\n\n\n\n\u001b[?1h\u001b=\u001b[?1h\u001b=  Restore completed in 153.34 ms for /work/verisol/Sources/BoogieAST/BoogieAST.csproj.\n  Restore completed in 41.34 ms for /work/verisol/Sources/ExternalToolsManager/ExternalToolsManager.csproj.\n  Restore completed in 22.62 ms for /work/verisol/Sources/SolToBoogie/SolToBoogie.csproj.\n  Restore completed in 17.39 ms for /work/verisol/Sources/SolToBoogieTest/SolToBoogieTest.csproj.\n  Restore completed in 17.98 ms for /work/verisol/Sources/SolidityAST/SolidityAST.csproj.\n  Restore completed in 14.47 ms for /work/verisol/Sources/SolidityCFG/SolidityCFG.csproj.\n  Restore completed in 16.9 ms for /work/verisol/Sources/VeriSol/VeriSol.csproj.\n  BoogieAST -> /work/verisol/bin/Debug/BoogieAST.dll\n  SolidityAST -> /work/verisol/bin/Debug/SolidityAST.dll\n\u001b[m\u001b[33mProcedureTranslator.cs(16,18): warning CS0659: 'ProcedureTranslator' overrides Object.Equals(object o) but does not override Object.GetHashCode() [/work/verisol/Sources/SolToBoogie/SolToBoogie.csproj]\n\u001b[m  SolToBoogie -> /work/verisol/bin/Debug/SolToBoogie.dll\n  SolidityCFG -> /work/verisol/bin/Debug/SolidityCFG.dll\n  ExternalToolsManager -> /work/verisol/bin/Debug/ExternalToolsManager.dll\n  SolToBoogieTest -> /work/verisol/bin/Debug/SolToBoogieTest.dll\n  SolToBoogieTest -> /work/verisol/bin/Debug/publish/\n  Successfully created package '/work/verisol/nupkg/SolToBoogieTest.0.1.5-alpha.nupkg'.\n  VeriSol -> /work/verisol/bin/Debug/VeriSol.dll\n  VeriSol -> /work/verisol/bin/Debug/publish/\n  Successfully created package '/work/verisol/nupkg/VeriSol.0.1.5-alpha.nupkg'.\n\u001b[m\u001b[32m\nBuild succeeded.\n\u001b[m\n\u001b[m\u001b[33mProcedureTranslator.cs(16,18): warning CS0659: 'ProcedureTranslator' overrides Object.Equals(object o) but does not override Object.GetHashCode() [/work/verisol/Sources/SolToBoogie/SolToBoogie.csproj]\n\u001b[m\u001b[m\u001b[33m    1 Warning(s)\n\u001b[m    0 Error(s)\n\u001b[m\nTime Elapsed 00:00:05.96\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import anvil.server\nanvil.server.connect(\"server_ZFIQMJB4URWM7V75MDXTD4R5-FNQ76OID3FCLIPND\")\nimport os\nimport os.path\nfrom os import path\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n# Importing the T5 modules from huggingface/transformers\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom rich.table import Column, Table\nfrom rich import box\nfrom rich.console import Console\n\n'''\nthis is for debuggin purpose of the pipeline\nit should be supplied by user from the app \n'''\nCONTRACT_PATH = ''\nuser_params = {\n      '1': '/content/drive/MyDrive/model_files',\n      '2': '/content/drive/MyDrive/LoopFor.sol,LoopFor',\n      '3': '/content/drive/MyDrive/pred.txt',\n      '4': '/content/drive/MyDrive/sample.txt'\n      }\ntest_params = {\n      'batch_size': 8,\n      'shuffle': False,\n      'num_workers': 0\n      }","metadata":{"id":"hF8kLnkuFJt6","cell_id":"9b45df8d96b04980ad1ef082128d8c81","source_hash":"fd8aeb19","execution_start":1677443771864,"execution_millis":6529,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Connecting to wss://anvil.works/uplink\nAnvil websocket open\nConnected to \"Default Environment\" as SERVER\n2023-02-26 20:36:13.423844: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-26 20:36:13.551967: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2023-02-26 20:36:13.556754: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-02-26 20:36:13.556771: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-02-26 20:36:13.579927: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-02-26 20:36:15.374501: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-02-26 20:36:15.374566: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-02-26 20:36:15.374573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class TestDataSetClass(Dataset):\n  \"\"\"\n  Creating a custom dataset for reading the dataset and \n  loading it into the dataloader to pass it to the neural network for finetuning the model\n\n  \"\"\"\n\n  def __init__(self, dataframe, tokenizer, source_len, source_text):\n    self.tokenizer = tokenizer\n    self.data = dataframe\n    self.source_len = source_len\n    self.source_text = self.data[source_text]\n\n  def __len__(self):\n    return len(self.source_text)\n\n  def __getitem__(self, index):\n    source_text = str(self.source_text[index])\n\n    #cleaning data so as to ensure data is in string type\n    source_text = ' '.join(source_text.split())\n    source = self.tokenizer.batch_encode_plus([source_text], \\\n                                              max_length=self.source_len, \\\n                                              pad_to_max_length=True, \\\n                                              truncation=True, \\\n                                              padding=\"max_length\",\\\n                                              return_tensors='pt')\n\n    source_ids = source['input_ids'].squeeze()\n    source_mask = source['attention_mask'].squeeze()\n\n    return {\n        'source_ids': source_ids.to(dtype=torch.long), \n        'source_mask': source_mask.to(dtype=torch.long), \n    }","metadata":{"id":"o3k-aWWIKpsU","cell_id":"72ece796268649ba9e043bbb7db520f9","source_hash":"685602cb","execution_start":1677443778410,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#test how the model performs on never-seen test contracts\n\n@anvil.server.callable\ndef predict_contract(saved_model_path, test_contract_path, prediction_file):\n   #in test_contract_path, user should specify path, contract name arguments\n   global CONTRACT_PATH \n   CONTRACT_PATH = test_contract_path\n   contracts = test_contract_path.split(',') \n   if saved_model_path == 'no':\n      model = T5ForConditionalGeneration.from_pretrained('sallywww/invariants-model')\n   else:\n      model = T5ForConditionalGeneration.from_pretrained(saved_model_path)  \n   tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n   col = ['Test']\n   f = open(contracts[0], \"r\")\n   file = f.read()\n   df = pd.DataFrame([file], columns=col)\n   col = ['Test']\n   df = pd.DataFrame([file], columns=col)\n   model.eval()\n   test_val = TestDataSetClass(df, tokenizer, source_len=512, source_text=\"Test\")\n   test_loader = DataLoader(test_val, **test_params)\n   predictions = []\n   with torch.no_grad():\n      for _, data in enumerate(test_loader, 0):\n          ids = data['source_ids']\n          mask = data['source_mask']\n          generated_ids = model.generate(\n              input_ids = ids,\n              attention_mask = mask, \n              max_length=150, \n              num_beams=2,\n              repetition_penalty=2.5, \n              length_penalty=1.0, \n              early_stopping=True\n              )\n          preds = [tokenizer.decode(g, skip_special_tokens=True, \\\n                                    clean_up_tokenization_spaces=True) for g in generated_ids]\n          predictions.extend(preds)\n   if prediction_file != 'no': \n      with open(prediction_file, 'w') as writefile:\n          for line in predictions:\n            writefile.write(line + '\\n')\n   with open('contract.sol', 'w') as writefile:\n      for line in predictions:\n        writefile.write(line + '\\n')\n   return predictions","metadata":{"id":"1jaZiyYNJ2JC","cell_id":"b62c49cc1e03454f9514bd73d4afdb2c","source_hash":"96fd5450","execution_start":1677443778411,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"@anvil.server.callable\ndef run_verisol(verify_original_contract, verisol_flags, \\\n                verification_result_path):\n  if path.exists('/work/boogie.txt'):\n      os.remove('/work/boogie.txt')\n  if path.exists('/work/corral.txt'):\n      os.remove('/work/corral.txt')\n  boogie_file = []\n  if verify_original_contract == 'yes':\n    contracts = CONTRACT_PATH.split(',')\n    print(contracts)\n    var1 = contracts[0]\n    var2 = contracts[1]\n    var3 = verisol_flags\n    !dotnet /work/verisol/bin/Debug/VeriSol.dll $'{var1}' $'{var2}' $'{var3}'\n    with open('/work/boogie.txt', 'r') as boogief: \n        for line in boogief:\n          boogie_file.extend([line])\n        if verification_result_path != None: \n          with open(verification_result_path, 'w') as writefile:\n            for line in boogief:\n              writefile.write(line +'\\n')\n        if path.exists('/work/corral.txt'):\n          with open('/work/corral.txt', 'r') as corraltxt: \n            boogie_file.extend(['Proof not found! Below is bounded model checking results from Corral:\\n'])\n            for line in corraltxt:            \n              boogie_file.extend([line])\n            \n  else:\n    var1 ='/work/contract.sol'\n    var2 = contracts[1]\n    var3 = verisol_flags\n    !dotnet /work/verisol/bin/Debug/VeriSol.dll $'{var1}' $'{var2}' $'{var3}'\n    with open('/work/boogie.txt', 'r') as boogief: \n        for line in boogief:\n          boogie_file.extend([line])\n        if verification_result_path != 'no': \n          with open(verification_result_path, 'w') as writefile:\n            for line in boogief:\n              writefile.write(line +'\\n')\n        if path.exists('/work/corral.txt'):\n          with open('/work/corral.txt', 'r') as corraltxt: \n            boogie_file.extend(['Proof not found! Below is bounded model checking results from Corral:\\n'])\n            for line in corraltxt:            \n              boogie_file.extend([line])\n\n  return boogie_file","metadata":{"id":"zJmK2K_-Kdpl","cell_id":"55b0ef39731f4358a4c4f8f343602168","source_hash":"6f534c2b","execution_start":1677443778452,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"code","source":"anvil.server.wait_forever()","metadata":{"id":"tcwHDnJmMAoo","colab":{"height":276,"base_uri":"https://localhost:8080/"},"cell_id":"c665de3fd6a743dd879e2f26fd193e57","outputId":"73992ca9-7c68-4fa6-ee3c-22aae3d9f574","source_hash":"7ae2c9df","execution_start":1677443778453,"execution_millis":54775005,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d0de821e-6b37-422f-9bbc-a2df12491510' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"deepnote":{},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"deepnote_app_layout":"dashboard","deepnote_notebook_id":"61aba64c09654268b351c336e9450a71","deepnote_persisted_session":{"createdAt":"2023-02-26T04:31:13.893Z"},"deepnote_execution_queue":[]}}