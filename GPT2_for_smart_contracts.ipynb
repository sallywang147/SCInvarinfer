{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sallywang147/SCInvarinfer/blob/main/GPT2_for_smart_contracts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbwl6E1E205R",
        "outputId": "bfc3ed65-c328-43a3-9a06-2769cc76dde5"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install rich[jupyter]"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rich[jupyter] in /usr/local/lib/python3.8/dist-packages (13.3.1)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from rich[jupyter]) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich[jupyter]) (4.5.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.8/dist-packages (from rich[jupyter]) (2.14.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.5.1 in /usr/local/lib/python3.8/dist-packages (from rich[jupyter]) (7.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (3.0.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (7.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (3.6.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (5.3.4)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]) (5.7.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich[jupyter]) (0.1.2)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.18.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.0.10)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (5.2.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (21.3.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.13.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.16.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (5.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.0.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (23.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (6.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.6.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.7.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.2.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.16.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (5.12.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.5.1->rich[jupyter]) (3.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from numpy import random\n",
        "import gspread\n",
        "import gc\n",
        "#autenticating to google\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "Fh27w8VgXnw3"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6nEben93JAk"
      },
      "source": [
        "import pandas as pd\n",
        "#defining my worksheet\n",
        "worksheet = gc.open('invariants3').sheet1\n",
        "#get_all_values gives a list of rows\n",
        "rows = worksheet.get_all_values()\n",
        "#Convert to a DataFrame \n",
        "cols = ['Source', 'Target', 'Verify_Success']\n",
        "df = pd.DataFrame(rows, columns=cols)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suxgy7wC4IqL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "dd313cd0-28fc-4812-9a7b-2682a45fae19"
      },
      "source": [
        "df"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Source  \\\n",
              "0   pragma solidity >=0.4.24 <0.6.0; contract C {\\...   \n",
              "1   pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract A...   \n",
              "2   pragma solidity >=0.4.24<0.6.0;\\nimport \"./Lib...   \n",
              "3   pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract A...   \n",
              "4   pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract L...   \n",
              "..                                                ...   \n",
              "65  pragma solidity >=0.4.24 <0.6.0;\\n\\n// This te...   \n",
              "66  pragma solidity >=0.4.24 <0.6.0;\\ncontract B {...   \n",
              "67  pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract E...   \n",
              "68  // SPDX-License-Identifier: MIT\\npragma experi...   \n",
              "69  pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract B...   \n",
              "\n",
              "                                               Target Verify_Success  \n",
              "0   pragma solidity >=0.4.24 <0.6.0; contract C {\\...              1  \n",
              "1   pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract A...              1  \n",
              "2   pragma solidity >=0.4.24<0.6.0;\\nimport \"./Lib...              0  \n",
              "3   pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract A...              1  \n",
              "4   pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract L...              1  \n",
              "..                                                ...            ...  \n",
              "65  pragma solidity >=0.4.24 <0.6.0;\\n\\n// This te...                 \n",
              "66  pragma solidity >=0.4.24 <0.6.0;\\ncontract B {...                 \n",
              "67  pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract E...                 \n",
              "68  // SPDX-License-Identifier: MIT\\npragma experi...                 \n",
              "69  pragma solidity >=0.4.24 <0.6.0;\\n\\ncontract B...                 \n",
              "\n",
              "[70 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2ba4494-ff43-4b93-b842-8e5598f9390b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Target</th>\n",
              "      <th>Verify_Success</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0; contract C {\\...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0; contract C {\\...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract A...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pragma solidity &gt;=0.4.24&lt;0.6.0;\\nimport \"./Lib...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24&lt;0.6.0;\\nimport \"./Lib...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract A...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract L...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract L...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\n// This te...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\n// This te...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\ncontract B {...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\ncontract B {...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract E...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract E...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>// SPDX-License-Identifier: MIT\\npragma experi...</td>\n",
              "      <td>// SPDX-License-Identifier: MIT\\npragma experi...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract B...</td>\n",
              "      <td>pragma solidity &gt;=0.4.24 &lt;0.6.0;\\n\\ncontract B...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2ba4494-ff43-4b93-b842-8e5598f9390b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2ba4494-ff43-4b93-b842-8e5598f9390b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2ba4494-ff43-4b93-b842-8e5598f9390b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB441x104K-o"
      },
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import random\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "\n",
        "from rich.table import Column, Table\n",
        "from rich import box\n",
        "from rich.console import Console\n",
        "\n",
        "# define a rich console logger\n",
        "console=Console(record=True)\n",
        "\n",
        "def display_df(df):\n",
        "  \"\"\"display dataframe in ASCII format\"\"\"\n",
        "\n",
        "  console=Console()\n",
        "  table = Table(Column(\"source_text\", justify=\"center\" ), Column(\"target_text\", justify=\"center\"), title=\"Sample Data\",pad_edge=False, box=box.ASCII)\n",
        "\n",
        "  for i, row in enumerate(df.values.tolist()):\n",
        "    table.add_row(row[0], row[1])\n",
        "\n",
        "  console.print(table)\n",
        "\n",
        "def plot_loss(index_list, loss_list):\n",
        "  results = {\n",
        "      \"epochs\": index_list,\n",
        "      \"cross entropy loss\": loss_list,\n",
        "  }\n",
        "  df = pd.DataFrame(results)\n",
        "  fig = px.line(df, x =\"epochs\", y=\"cross entropy loss\",  title=\"Evaluation\")\n",
        "  fig.show()\n",
        "\n",
        "training_logger = Table(Column(\"Epoch\", justify=\"center\" ),\n",
        "                        Column(\"Cross Entropy Loss\", justify=\"center\"), \n",
        "                        title=\"Training Status\",pad_edge=False, box=box.ASCII)\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlYaKW9h4ai_"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_params={\n",
        "    \"MODEL\":\"gpt2\",             # model_type: t5-large\n",
        "    \"MAX_LENGTH\": 1024,  # max length of source text\n",
        "   # \"SEED\": random.randint(1000)    # randomized seeds to shuffle test set\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "ERK2ty5Q6Rdy"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vLQPGAn4v17"
      },
      "source": [
        "class GPTDataSetClass(Dataset):\n",
        "  \"\"\"\n",
        "  Creating a custom dataset for reading the dataset and \n",
        "  loading it into the dataloader to pass it to the neural network for finetuning the model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, target_label, truncate=False, \\\n",
        "               gpt2_type=model_params['MODEL'], \\\n",
        "               max_length=model_params[\"MAX_LENGTH\"]):\n",
        "    self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "    self.target_tokens = []\n",
        "\n",
        "    for row in df['Target']:\n",
        "        self.target_tokens.append(torch.tensor(\n",
        "            self.tokenizer.encode(f\"<|{target_label}|>{row[:max_length]}<|endoftext|>\")\n",
        "            ))  \n",
        "    if truncate:\n",
        "            self.target_tokens = self.target_tokens[:20000]\n",
        "    self.length = len(self.target_tokens)   \n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.target_tokens[index]   "
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accumulated batch size (since GPT2 is so big)\n",
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
        "        return packed_tensor, True, None"
      ],
      "metadata": {
        "id": "gJ2ccsedzcAW"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    dataset, model, tokenizer,\n",
        "    batch_size=16, epochs=100, lr=2e-5,\n",
        "    max_seq_len=400, warmup_steps=200,\n",
        "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
        "    test_mode=False, save_model_on_epoch=False,\n",
        "):\n",
        "    acc_steps = 100\n",
        "    device=torch.device(\"cuda\")\n",
        "    model = model.cuda()\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "    loss=0\n",
        "    accumulating_batch_count = 0\n",
        "    input_tensor = None\n",
        "    loss_list = []\n",
        "    epoch_list = []\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = []\n",
        "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
        "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
        "\n",
        "            if carry_on and idx != len(train_dataloader) - 1:\n",
        "                continue\n",
        "\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            outputs = model(input_tensor, labels=input_tensor)  \n",
        "            loss = outputs[0] \n",
        "            total_loss.append(float(loss.item()))       \n",
        "            loss.backward()                      \n",
        "            if (accumulating_batch_count % batch_size) == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "  \n",
        "            accumulating_batch_count += 1\n",
        "            input_tensor = None\n",
        "\n",
        "        training_logger.add_row(str(epoch), str(np.mean(total_loss)))       \n",
        "        if save_model_on_epoch:\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
        "            )\n",
        "        loss_list.append(np.mean(total_loss))\n",
        "        epoch_list.append(epoch) \n",
        "        print(f\"for epoch {epoch} the loss is {np.mean(total_loss)}\\n\")\n",
        "    console.print(training_logger)   \n",
        "    plot_loss(epoch_list, loss_list)\n",
        "    return model"
      ],
      "metadata": {
        "id": "PTVyI2fzzn3P"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_GPT2(df, model_params):   \n",
        "  console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
        "\n",
        "  # tokenzier for encoding the text\n",
        "  dataset = GPTDataSetClass(df['Target'], truncate=False, gpt2_type=model_params[\"MODEL\"]) \n",
        "  #Get the tokenizer and model\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_params[\"MODEL\"])  \n",
        "  trained_model = train(dataset, model, tokenizer)\n",
        "  console.log(f\"[Saving Model]...\\n\")\n",
        "  #Saving the model after training\n",
        "  path = os.path.join('/content/output', \"model_files\")\n",
        "  model.save_pretrained(path)\n",
        "  tokenizer.save_pretrained(path)\n",
        "  console.print(f\"\"\"[Model] Model saved @ {os.path.join('/content/output', \"model_files\")}\\n\"\"\")\n",
        "  \n",
        "  # logging\n",
        "  console.log(f\"[Data]: Reading Raw data...\\n\")\n",
        "\n",
        "  # Importing the raw dataset\n",
        "  display_df(df.head(2))\n",
        "\n",
        "  # Creation of Dataset and Dataloader\n",
        "  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
        "\n",
        "  console.print(f\"FULL Dataset: {df.shape}\")\n",
        "  return trained_model, tokenizer\n"
      ],
      "metadata": {
        "id": "nOHr5lM82h53"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    prompt,\n",
        "    entry_count=10,\n",
        "    entry_length=100, #maximum number of words\n",
        "    top_p=0.8,\n",
        "    temperature=1.,\n",
        "):\n",
        "    model.eval()\n",
        "    generated_num = 0\n",
        "    generated_list = []\n",
        "\n",
        "    filter_value = -float(\"Inf\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for entry_idx in trange(entry_count):\n",
        "\n",
        "            entry_finished = False\n",
        "            generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "\n",
        "            for i in range(entry_length):\n",
        "                outputs = model(generated, labels=generated)\n",
        "                loss, logits = outputs[:2]\n",
        "                logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n",
        "\n",
        "                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "                sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[\n",
        "                    ..., :-1\n",
        "                ].clone()\n",
        "                sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "                logits[:, indices_to_remove] = filter_value\n",
        "\n",
        "                next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
        "                generated = torch.cat((generated, next_token), dim=1)\n",
        "\n",
        "                if next_token in tokenizer.encode(\"<|endoftext|>\"):\n",
        "                    entry_finished = True\n",
        "\n",
        "                if entry_finished:\n",
        "\n",
        "                    generated_num = generated_num + 1\n",
        "\n",
        "                    output_list = list(generated.squeeze().numpy())\n",
        "                    output_text = tokenizer.decode(output_list)\n",
        "                    generated_list.append(output_text + '\\n')\n",
        "                    break\n",
        "            \n",
        "            if not entry_finished:\n",
        "              output_list = list(generated.squeeze().numpy())\n",
        "              output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n",
        "              generated_list.append(output_text + '\\n')\n",
        "                \n",
        "    return generated_list\n",
        "\n",
        "#Function to generate multiple sentences. Test data should be a dataframe\n",
        "def text_generation(model, tokenizer, test_data):\n",
        "  generated_code = []\n",
        "  for i in range(len(test_data)):\n",
        "    x = generate(model.to('cpu'), tokenizer, test_data['Target'][i], entry_count=1)\n",
        "    generated_code.append(x)\n",
        "  return generated_code\n",
        "\n",
        "#Run the functions to generate the lyrics\n",
        "\n",
        "def test_fine_tuned_gpt2(model, tokenizer, df): \n",
        "    test_set = df.sample(n=1)\n",
        "    df = df.loc[~df.index.isin(test_set.index)]\n",
        "\n",
        "    #Reset the indexes\n",
        "    test_set = test_set.reset_index()\n",
        "    df = df.reset_index()\n",
        "\n",
        "    #For the test set only, keep last 20 words in a new column, then remove them from original column\n",
        "    test_set['Target'] = test_set['Target'].str.split().apply(' '.join)\n",
        "    test_set['Source'] = test_set['Source'].str.split().apply(' '.join)\n",
        "    generated_code = text_generation(model, tokenizer, test_set)\n",
        "    print(generated_code)\n"
      ],
      "metadata": {
        "id": "ujnNVivM1bMq"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, tokenizer = fine_tune_GPT2(df, model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZWASVuBB9lLo",
        "outputId": "2057c2c4-7750-4903-805f-52a43cd30d13"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[05:49:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading gpt2\u001b[33m...\u001b[0m                                              \u001b[2m<ipython-input-154-892678bfe71c>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m2\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05:49:00] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading gpt2<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-154-892678bfe71c&gt;:2</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning:\n",
            "\n",
            "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\n",
            "70it [00:01, 36.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 0 the loss is 2.1436794417245046\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 1 the loss is 2.1546644960130963\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 2 the loss is 2.1675391129084995\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 3 the loss is 2.0983209133148195\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 4 the loss is 2.1102750403540473\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 5 the loss is 2.0934676136289325\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 6 the loss is 2.0477966002055576\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 7 the loss is 2.0224364825657437\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 8 the loss is 1.9751564979553222\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 9 the loss is 1.9974298988069807\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 10 the loss is 1.917651949610029\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 11 the loss is 1.8988139356885638\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 12 the loss is 1.8488697460719516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 13 the loss is 1.8543871470860072\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 14 the loss is 1.7937614304678782\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 15 the loss is 1.8094140257154192\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 16 the loss is 1.7423927477427892\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 39.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 17 the loss is 1.7213052340916224\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 18 the loss is 1.6275350638798305\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 19 the loss is 1.6947321823665074\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 20 the loss is 1.6338645117623465\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 21 the loss is 1.608501250403268\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 22 the loss is 1.614155776160104\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 23 the loss is 1.5558397940226965\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 24 the loss is 1.5421142305646625\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 25 the loss is 1.600668134008135\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 26 the loss is 1.4860668965748378\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 27 the loss is 1.435118395941598\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 28 the loss is 1.4278333153043474\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 29 the loss is 1.3933745792933874\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 30 the loss is 1.4189755541937692\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 31 the loss is 1.432232471874782\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 32 the loss is 1.3290056432996478\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 33 the loss is 1.278752522809165\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 34 the loss is 1.2585791911397661\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 39.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 35 the loss is 1.2251608644212995\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 39.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 36 the loss is 1.1671622565814428\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 39.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 37 the loss is 1.1581524065562656\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 38 the loss is 1.1070636970656258\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 39 the loss is 1.1232171399252755\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 40 the loss is 1.0450428775378635\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 41 the loss is 1.0431985872132437\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 42 the loss is 1.0646429538726807\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 43 the loss is 1.068264901638031\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 44 the loss is 0.9731387019157409\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 45 the loss is 0.9354864001274109\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 46 the loss is 0.930291337626321\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 47 the loss is 0.8767782466752189\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 48 the loss is 0.9218717115265983\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 49 the loss is 0.9437644728592464\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 50 the loss is 0.7849452078342438\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 51 the loss is 0.816523551940918\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 52 the loss is 0.7790768018790654\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 53 the loss is 0.7887677678040096\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 54 the loss is 0.7330869708742415\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 55 the loss is 0.7711141756602696\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 56 the loss is 0.7857509825910841\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 57 the loss is 0.7330791958740779\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 58 the loss is 0.6877000706536429\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 59 the loss is 0.6911370703152248\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 60 the loss is 0.723379750762667\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 61 the loss is 0.6953159425939832\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 62 the loss is 0.6415342330932617\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 63 the loss is 0.731751309973853\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 64 the loss is 0.695586792060307\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 65 the loss is 0.6058397608143943\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 66 the loss is 0.6443925248725074\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 67 the loss is 0.6899393149784633\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 68 the loss is 0.7188938430377415\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 69 the loss is 0.6081328421831131\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 70 the loss is 0.5565617510250637\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 71 the loss is 0.5680598301546914\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 72 the loss is 0.6768809825181961\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 73 the loss is 0.5179834906544004\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 74 the loss is 0.527499685542924\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 75 the loss is 0.6377404962267195\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 76 the loss is 0.5531202588762556\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 77 the loss is 0.6289371741669518\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 78 the loss is 0.6059482323271888\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 79 the loss is 0.5610349438020161\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 80 the loss is 0.5432909744126456\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 81 the loss is 0.5481607313667025\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 82 the loss is 0.5343977442809513\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 83 the loss is 0.5170002371072769\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 84 the loss is 0.516483929327556\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 85 the loss is 0.561349076458386\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 86 the loss is 0.5032046113695418\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 87 the loss is 0.5026288960661207\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 88 the loss is 0.5201784500053951\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 89 the loss is 0.5510805376938411\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 36.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 90 the loss is 0.5864335094179426\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 91 the loss is 0.5751040948288781\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 92 the loss is 0.5418557392699378\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 93 the loss is 0.5006887878690447\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 94 the loss is 0.5638578717197691\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 95 the loss is 0.4967465783868517\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 96 the loss is 0.45932091559682575\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 39.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 97 the loss is 0.4984339611870902\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 38.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 98 the loss is 0.4964844158717564\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "70it [00:01, 37.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for epoch 99 the loss is 0.5937005111149379\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m       Training Status       \u001b[0m\n",
              "+---------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mCross Entropy Loss \u001b[0m|\n",
              "|------+--------------------|\n",
              "|  0   | 2.1436794417245046 |\n",
              "|  1   | 2.1546644960130963 |\n",
              "|  2   | 2.1675391129084995 |\n",
              "|  3   | 2.0983209133148195 |\n",
              "|  4   | 2.1102750403540473 |\n",
              "|  5   | 2.0934676136289325 |\n",
              "|  6   | 2.0477966002055576 |\n",
              "|  7   | 2.0224364825657437 |\n",
              "|  8   | 1.9751564979553222 |\n",
              "|  9   | 1.9974298988069807 |\n",
              "| 10   |  1.917651949610029 |\n",
              "| 11   | 1.8988139356885638 |\n",
              "| 12   | 1.8488697460719516 |\n",
              "| 13   | 1.8543871470860072 |\n",
              "| 14   | 1.7937614304678782 |\n",
              "| 15   | 1.8094140257154192 |\n",
              "| 16   | 1.7423927477427892 |\n",
              "| 17   | 1.7213052340916224 |\n",
              "| 18   | 1.6275350638798305 |\n",
              "| 19   | 1.6947321823665074 |\n",
              "| 20   | 1.6338645117623465 |\n",
              "| 21   |  1.608501250403268 |\n",
              "| 22   |  1.614155776160104 |\n",
              "| 23   | 1.5558397940226965 |\n",
              "| 24   | 1.5421142305646625 |\n",
              "| 25   |  1.600668134008135 |\n",
              "| 26   | 1.4860668965748378 |\n",
              "| 27   |  1.435118395941598 |\n",
              "| 28   | 1.4278333153043474 |\n",
              "| 29   | 1.3933745792933874 |\n",
              "| 30   | 1.4189755541937692 |\n",
              "| 31   |  1.432232471874782 |\n",
              "| 32   | 1.3290056432996478 |\n",
              "| 33   |  1.278752522809165 |\n",
              "| 34   | 1.2585791911397661 |\n",
              "| 35   | 1.2251608644212995 |\n",
              "| 36   | 1.1671622565814428 |\n",
              "| 37   | 1.1581524065562656 |\n",
              "| 38   | 1.1070636970656258 |\n",
              "| 39   | 1.1232171399252755 |\n",
              "| 40   | 1.0450428775378635 |\n",
              "| 41   | 1.0431985872132437 |\n",
              "| 42   | 1.0646429538726807 |\n",
              "| 43   |  1.068264901638031 |\n",
              "| 44   | 0.9731387019157409 |\n",
              "| 45   | 0.9354864001274109 |\n",
              "| 46   |  0.930291337626321 |\n",
              "| 47   | 0.8767782466752189 |\n",
              "| 48   | 0.9218717115265983 |\n",
              "| 49   | 0.9437644728592464 |\n",
              "| 50   | 0.7849452078342438 |\n",
              "| 51   |  0.816523551940918 |\n",
              "| 52   | 0.7790768018790654 |\n",
              "| 53   | 0.7887677678040096 |\n",
              "| 54   | 0.7330869708742415 |\n",
              "| 55   | 0.7711141756602696 |\n",
              "| 56   | 0.7857509825910841 |\n",
              "| 57   | 0.7330791958740779 |\n",
              "| 58   | 0.6877000706536429 |\n",
              "| 59   | 0.6911370703152248 |\n",
              "| 60   |  0.723379750762667 |\n",
              "| 61   | 0.6953159425939832 |\n",
              "| 62   | 0.6415342330932617 |\n",
              "| 63   |  0.731751309973853 |\n",
              "| 64   |  0.695586792060307 |\n",
              "| 65   | 0.6058397608143943 |\n",
              "| 66   | 0.6443925248725074 |\n",
              "| 67   | 0.6899393149784633 |\n",
              "| 68   | 0.7188938430377415 |\n",
              "| 69   | 0.6081328421831131 |\n",
              "| 70   | 0.5565617510250637 |\n",
              "| 71   | 0.5680598301546914 |\n",
              "| 72   | 0.6768809825181961 |\n",
              "| 73   | 0.5179834906544004 |\n",
              "| 74   |  0.527499685542924 |\n",
              "| 75   | 0.6377404962267195 |\n",
              "| 76   | 0.5531202588762556 |\n",
              "| 77   | 0.6289371741669518 |\n",
              "| 78   | 0.6059482323271888 |\n",
              "| 79   | 0.5610349438020161 |\n",
              "| 80   | 0.5432909744126456 |\n",
              "| 81   | 0.5481607313667025 |\n",
              "| 82   | 0.5343977442809513 |\n",
              "| 83   | 0.5170002371072769 |\n",
              "| 84   |  0.516483929327556 |\n",
              "| 85   |  0.561349076458386 |\n",
              "| 86   | 0.5032046113695418 |\n",
              "| 87   | 0.5026288960661207 |\n",
              "| 88   | 0.5201784500053951 |\n",
              "| 89   | 0.5510805376938411 |\n",
              "| 90   | 0.5864335094179426 |\n",
              "| 91   | 0.5751040948288781 |\n",
              "| 92   | 0.5418557392699378 |\n",
              "| 93   | 0.5006887878690447 |\n",
              "| 94   | 0.5638578717197691 |\n",
              "| 95   | 0.4967465783868517 |\n",
              "| 96   | 0.45932091559682575|\n",
              "| 97   | 0.4984339611870902 |\n",
              "| 98   | 0.4964844158717564 |\n",
              "| 99   | 0.5937005111149379 |\n",
              "+---------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">       Training Status       </span>\n",
              "+---------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Cross Entropy Loss </span>|\n",
              "|------+--------------------|\n",
              "|  0   | 2.1436794417245046 |\n",
              "|  1   | 2.1546644960130963 |\n",
              "|  2   | 2.1675391129084995 |\n",
              "|  3   | 2.0983209133148195 |\n",
              "|  4   | 2.1102750403540473 |\n",
              "|  5   | 2.0934676136289325 |\n",
              "|  6   | 2.0477966002055576 |\n",
              "|  7   | 2.0224364825657437 |\n",
              "|  8   | 1.9751564979553222 |\n",
              "|  9   | 1.9974298988069807 |\n",
              "| 10   |  1.917651949610029 |\n",
              "| 11   | 1.8988139356885638 |\n",
              "| 12   | 1.8488697460719516 |\n",
              "| 13   | 1.8543871470860072 |\n",
              "| 14   | 1.7937614304678782 |\n",
              "| 15   | 1.8094140257154192 |\n",
              "| 16   | 1.7423927477427892 |\n",
              "| 17   | 1.7213052340916224 |\n",
              "| 18   | 1.6275350638798305 |\n",
              "| 19   | 1.6947321823665074 |\n",
              "| 20   | 1.6338645117623465 |\n",
              "| 21   |  1.608501250403268 |\n",
              "| 22   |  1.614155776160104 |\n",
              "| 23   | 1.5558397940226965 |\n",
              "| 24   | 1.5421142305646625 |\n",
              "| 25   |  1.600668134008135 |\n",
              "| 26   | 1.4860668965748378 |\n",
              "| 27   |  1.435118395941598 |\n",
              "| 28   | 1.4278333153043474 |\n",
              "| 29   | 1.3933745792933874 |\n",
              "| 30   | 1.4189755541937692 |\n",
              "| 31   |  1.432232471874782 |\n",
              "| 32   | 1.3290056432996478 |\n",
              "| 33   |  1.278752522809165 |\n",
              "| 34   | 1.2585791911397661 |\n",
              "| 35   | 1.2251608644212995 |\n",
              "| 36   | 1.1671622565814428 |\n",
              "| 37   | 1.1581524065562656 |\n",
              "| 38   | 1.1070636970656258 |\n",
              "| 39   | 1.1232171399252755 |\n",
              "| 40   | 1.0450428775378635 |\n",
              "| 41   | 1.0431985872132437 |\n",
              "| 42   | 1.0646429538726807 |\n",
              "| 43   |  1.068264901638031 |\n",
              "| 44   | 0.9731387019157409 |\n",
              "| 45   | 0.9354864001274109 |\n",
              "| 46   |  0.930291337626321 |\n",
              "| 47   | 0.8767782466752189 |\n",
              "| 48   | 0.9218717115265983 |\n",
              "| 49   | 0.9437644728592464 |\n",
              "| 50   | 0.7849452078342438 |\n",
              "| 51   |  0.816523551940918 |\n",
              "| 52   | 0.7790768018790654 |\n",
              "| 53   | 0.7887677678040096 |\n",
              "| 54   | 0.7330869708742415 |\n",
              "| 55   | 0.7711141756602696 |\n",
              "| 56   | 0.7857509825910841 |\n",
              "| 57   | 0.7330791958740779 |\n",
              "| 58   | 0.6877000706536429 |\n",
              "| 59   | 0.6911370703152248 |\n",
              "| 60   |  0.723379750762667 |\n",
              "| 61   | 0.6953159425939832 |\n",
              "| 62   | 0.6415342330932617 |\n",
              "| 63   |  0.731751309973853 |\n",
              "| 64   |  0.695586792060307 |\n",
              "| 65   | 0.6058397608143943 |\n",
              "| 66   | 0.6443925248725074 |\n",
              "| 67   | 0.6899393149784633 |\n",
              "| 68   | 0.7188938430377415 |\n",
              "| 69   | 0.6081328421831131 |\n",
              "| 70   | 0.5565617510250637 |\n",
              "| 71   | 0.5680598301546914 |\n",
              "| 72   | 0.6768809825181961 |\n",
              "| 73   | 0.5179834906544004 |\n",
              "| 74   |  0.527499685542924 |\n",
              "| 75   | 0.6377404962267195 |\n",
              "| 76   | 0.5531202588762556 |\n",
              "| 77   | 0.6289371741669518 |\n",
              "| 78   | 0.6059482323271888 |\n",
              "| 79   | 0.5610349438020161 |\n",
              "| 80   | 0.5432909744126456 |\n",
              "| 81   | 0.5481607313667025 |\n",
              "| 82   | 0.5343977442809513 |\n",
              "| 83   | 0.5170002371072769 |\n",
              "| 84   |  0.516483929327556 |\n",
              "| 85   |  0.561349076458386 |\n",
              "| 86   | 0.5032046113695418 |\n",
              "| 87   | 0.5026288960661207 |\n",
              "| 88   | 0.5201784500053951 |\n",
              "| 89   | 0.5510805376938411 |\n",
              "| 90   | 0.5864335094179426 |\n",
              "| 91   | 0.5751040948288781 |\n",
              "| 92   | 0.5418557392699378 |\n",
              "| 93   | 0.5006887878690447 |\n",
              "| 94   | 0.5638578717197691 |\n",
              "| 95   | 0.4967465783868517 |\n",
              "| 96   | 0.45932091559682575|\n",
              "| 97   | 0.4984339611870902 |\n",
              "| 98   | 0.4964844158717564 |\n",
              "| 99   | 0.5937005111149379 |\n",
              "+---------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"6565661f-1771-4af1-ada0-27f5824697dd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6565661f-1771-4af1-ada0-27f5824697dd\")) {                    Plotly.newPlot(                        \"6565661f-1771-4af1-ada0-27f5824697dd\",                        [{\"hovertemplate\":\"epochs=%{x}<br>cross entropy loss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[2.1436794417245046,2.1546644960130963,2.1675391129084995,2.0983209133148195,2.1102750403540473,2.0934676136289325,2.0477966002055576,2.0224364825657437,1.9751564979553222,1.9974298988069807,1.917651949610029,1.8988139356885638,1.8488697460719516,1.8543871470860072,1.7937614304678782,1.8094140257154192,1.7423927477427892,1.7213052340916224,1.6275350638798305,1.6947321823665074,1.6338645117623465,1.608501250403268,1.614155776160104,1.5558397940226965,1.5421142305646625,1.600668134008135,1.4860668965748378,1.435118395941598,1.4278333153043474,1.3933745792933874,1.4189755541937692,1.432232471874782,1.3290056432996478,1.278752522809165,1.2585791911397661,1.2251608644212995,1.1671622565814428,1.1581524065562656,1.1070636970656258,1.1232171399252755,1.0450428775378635,1.0431985872132437,1.0646429538726807,1.068264901638031,0.9731387019157409,0.9354864001274109,0.930291337626321,0.8767782466752189,0.9218717115265983,0.9437644728592464,0.7849452078342438,0.816523551940918,0.7790768018790654,0.7887677678040096,0.7330869708742415,0.7711141756602696,0.7857509825910841,0.7330791958740779,0.6877000706536429,0.6911370703152248,0.723379750762667,0.6953159425939832,0.6415342330932617,0.731751309973853,0.695586792060307,0.6058397608143943,0.6443925248725074,0.6899393149784633,0.7188938430377415,0.6081328421831131,0.5565617510250637,0.5680598301546914,0.6768809825181961,0.5179834906544004,0.527499685542924,0.6377404962267195,0.5531202588762556,0.6289371741669518,0.6059482323271888,0.5610349438020161,0.5432909744126456,0.5481607313667025,0.5343977442809513,0.5170002371072769,0.516483929327556,0.561349076458386,0.5032046113695418,0.5026288960661207,0.5201784500053951,0.5510805376938411,0.5864335094179426,0.5751040948288781,0.5418557392699378,0.5006887878690447,0.5638578717197691,0.4967465783868517,0.45932091559682575,0.4984339611870902,0.4964844158717564,0.5937005111149379],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"cross entropy loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Evaluation\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6565661f-1771-4af1-ada0-27f5824697dd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[05:52:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                    \u001b[2m<ipython-input-154-892678bfe71c>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m10\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                     \u001b[2m                                   \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05:52:08] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-154-892678bfe71c&gt;:10</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                   </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ \u001b[35m/content/output/\u001b[0m\u001b[95mmodel_files\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ <span style=\"color: #800080; text-decoration-color: #800080\">/content/output/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">model_files</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[05:52:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading Raw data\u001b[33m...\u001b[0m                                          \u001b[2m<ipython-input-154-892678bfe71c>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m18\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                                     \u001b[2m                                   \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05:52:10] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading Raw data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-154-892678bfe71c&gt;:18</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                   </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                                    Sample Data                                                    \u001b[0m\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n",
              "|\u001b[1m                      source_text                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                      target_text                      \u001b[0m|\n",
              "|--------------------------------------------------------+--------------------------------------------------------|\n",
              "|     pragma solidity >=0.4.24 <0.6.0; contract C {      |      pragma solidity >=0.4.24 <0.6.0; contract C {     |\n",
              "|                                                        |                                                        |\n",
              "|               function setOwner() public {             |                function setOwner() public {            |\n",
              "|                 address owner = tx.origin;             |                  address owner = tx.origin;            |\n",
              "|                  uint price = tx.gasprice;             |                   uint price = tx.gasprice;            |\n",
              "|                        uint x = now;                   |                         uint x = now;                  |\n",
              "|                            }                           |                             }                          |\n",
              "|                           }                            |                            }                           |\n",
              "|           pragma solidity >=0.4.24 <0.6.0;             |            pragma solidity >=0.4.24 <0.6.0;            |\n",
              "|                                                        |                                                        |\n",
              "|                     contract A {                       |                      contract A {                      |\n",
              "|            function testTuple() public pure{           |             function testTuple() public pure{          |\n",
              "|        // (uint a, uint b) = (1, 3); //cannot handle   |         // (uint a, uint b) = (1, 3); //cannot handle  |\n",
              "|            multiple declarations in tuples             |             multiple declarations in tuples            |\n",
              "|                           uint a;                      |                            uint a;                     |\n",
              "|                           uint b;                      |                            uint b;                     |\n",
              "|         /* only support function returns as tuples     |          /* only support function returns as tuples    |\n",
              "|                      (a,  b) = (1, 3);                 |                       (a,  b) = (1, 3);                |\n",
              "|                             */                         |                       assert (a == 1);                 |\n",
              "|                                                        |                       assert (b == 3);                 |\n",
              "|                   (a, b) = returnTuple();              |                              */                        |\n",
              "|                                                        |                                                        |\n",
              "|                (a, b) = returnTupleByName();           |                    (a, b) = returnTuple();             |\n",
              "|                                                        |                       assert (a == 4);                 |\n",
              "|        //(, b) = returnTuple(); //can;t handle null    |                       assert (b == 40);                |\n",
              "|                     placeholders                       |                                                        |\n",
              "|                     //assert (b == 40);                |                 (a, b) = returnTupleByName();          |\n",
              "|                            }                           |                       assert (a == 5);                 |\n",
              "|                                                        |                       assert (b == 55);                |\n",
              "|    function returnTuple() private pure returns (uint,  |                                                        |\n",
              "|                        uint){                          |         //(, b) = returnTuple(); //can;t handle null   |\n",
              "|                       return (4, 40);                  |                      placeholders                      |\n",
              "|                            }                           |                      //assert (b == 40);               |\n",
              "|                                                        |                             }                          |\n",
              "|    function returnTupleByName() private pure returns   |                                                        |\n",
              "|                   (uint a, uint b){                    |     function returnTuple() private pure returns (uint, |\n",
              "|                           a = 5;                       |                         uint){                         |\n",
              "|                           b = 55;                      |                        return (4, 40);                 |\n",
              "|                        return (a,b);                   |                             }                          |\n",
              "|                            }                           |                                                        |\n",
              "|                           }                            |     function returnTupleByName() private pure returns  |\n",
              "|                                                        |                    (uint a, uint b){                   |\n",
              "|                                                        |                            a = 5;                      |\n",
              "|                                                        |                            b = 55;                     |\n",
              "|                                                        |                         return (a,b);                  |\n",
              "|                                                        |                             }                          |\n",
              "|                                                        |                            }                           |\n",
              "|                                                        |                                                        |\n",
              "|                                                        |                                                        |\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Sample Data                                                    </span>\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">                      source_text                       </span>|<span style=\"font-weight: bold\">                       target_text                      </span>|\n",
              "|--------------------------------------------------------+--------------------------------------------------------|\n",
              "|     pragma solidity &gt;=0.4.24 &lt;0.6.0; contract C {      |      pragma solidity &gt;=0.4.24 &lt;0.6.0; contract C {     |\n",
              "|                                                        |                                                        |\n",
              "|               function setOwner() public {             |                function setOwner() public {            |\n",
              "|                 address owner = tx.origin;             |                  address owner = tx.origin;            |\n",
              "|                  uint price = tx.gasprice;             |                   uint price = tx.gasprice;            |\n",
              "|                        uint x = now;                   |                         uint x = now;                  |\n",
              "|                            }                           |                             }                          |\n",
              "|                           }                            |                            }                           |\n",
              "|           pragma solidity &gt;=0.4.24 &lt;0.6.0;             |            pragma solidity &gt;=0.4.24 &lt;0.6.0;            |\n",
              "|                                                        |                                                        |\n",
              "|                     contract A {                       |                      contract A {                      |\n",
              "|            function testTuple() public pure{           |             function testTuple() public pure{          |\n",
              "|        // (uint a, uint b) = (1, 3); //cannot handle   |         // (uint a, uint b) = (1, 3); //cannot handle  |\n",
              "|            multiple declarations in tuples             |             multiple declarations in tuples            |\n",
              "|                           uint a;                      |                            uint a;                     |\n",
              "|                           uint b;                      |                            uint b;                     |\n",
              "|         /* only support function returns as tuples     |          /* only support function returns as tuples    |\n",
              "|                      (a,  b) = (1, 3);                 |                       (a,  b) = (1, 3);                |\n",
              "|                             */                         |                       assert (a == 1);                 |\n",
              "|                                                        |                       assert (b == 3);                 |\n",
              "|                   (a, b) = returnTuple();              |                              */                        |\n",
              "|                                                        |                                                        |\n",
              "|                (a, b) = returnTupleByName();           |                    (a, b) = returnTuple();             |\n",
              "|                                                        |                       assert (a == 4);                 |\n",
              "|        //(, b) = returnTuple(); //can;t handle null    |                       assert (b == 40);                |\n",
              "|                     placeholders                       |                                                        |\n",
              "|                     //assert (b == 40);                |                 (a, b) = returnTupleByName();          |\n",
              "|                            }                           |                       assert (a == 5);                 |\n",
              "|                                                        |                       assert (b == 55);                |\n",
              "|    function returnTuple() private pure returns (uint,  |                                                        |\n",
              "|                        uint){                          |         //(, b) = returnTuple(); //can;t handle null   |\n",
              "|                       return (4, 40);                  |                      placeholders                      |\n",
              "|                            }                           |                      //assert (b == 40);               |\n",
              "|                                                        |                             }                          |\n",
              "|    function returnTupleByName() private pure returns   |                                                        |\n",
              "|                   (uint a, uint b){                    |     function returnTuple() private pure returns (uint, |\n",
              "|                           a = 5;                       |                         uint){                         |\n",
              "|                           b = 55;                      |                        return (4, 40);                 |\n",
              "|                        return (a,b);                   |                             }                          |\n",
              "|                            }                           |                                                        |\n",
              "|                           }                            |     function returnTupleByName() private pure returns  |\n",
              "|                                                        |                    (uint a, uint b){                   |\n",
              "|                                                        |                            a = 5;                      |\n",
              "|                                                        |                            b = 55;                     |\n",
              "|                                                        |                         return (a,b);                  |\n",
              "|                                                        |                             }                          |\n",
              "|                                                        |                            }                           |\n",
              "|                                                        |                                                        |\n",
              "|                                                        |                                                        |\n",
              "+-----------------------------------------------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m70\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_contrct(path, ratio): \n",
        "  col = ['Target']\n",
        "  f = open(path, \"r\")\n",
        "  file = f.read()\n",
        "  test_df = pd.DataFrame([file], columns=col)\n",
        "  program_length = len(test_df['Target'][0].split())\n",
        "  prompt_ratio = ratio\n",
        "  prompt_length = int(prompt_ratio * program_length)\n",
        "  return test_df, prompt_length\n",
        "\n",
        "test_df, n = generate_test_contrct('/content/LoopFor.sol', 0.5)"
      ],
      "metadata": {
        "id": "_hKPs7PCcuHJ"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_test(df, prompt_length):\n",
        "  copy_1 = df.copy(deep=True)\n",
        "  copy_2 = df.copy(deep=True)\n",
        "  #true\n",
        "  a = copy_1['Target'].str.split().str[-prompt_length:].apply(' '.join)[0]\n",
        "  #masked out program \n",
        "  b = copy_2['Target'].str.split().str[:-prompt_length].apply(' '.join)[0]\n",
        "  return a, b\n",
        "truth, prompt = truncate_test(test_df, n)\n",
        "col = ['Target']\n",
        "prompt_df = pd.DataFrame([prompt], columns=col)\n",
        "out = text_generation(trained_model, tokenizer, prompt_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_nSQ6y7NByw",
        "outputId": "70c0e664-f79b-433d-8bb8-69c457e0c93a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_df['Target'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMBf9RjAvHS-",
        "outputId": "069bc5a3-bc62-4316-e2a8-fad3ae9f3173"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pragma solidity ^0.4.24; import \"./../../Libraries/VeriSolContracts.sol\"; //import \"./VeriSolContracts.sol\"; //import \"github.com/microsoft/verisol/blob/master/Libraries/VeriSolContracts.sol\"; contract LoopFor { // test Loop invariant with for loop constructor(uint n) public { require (n >= 0); uint y = 0; for (uint x = n; x != 0; x --) { y++; } } // test Loop invariant with while loop function Foo(uint n) public {\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYi_yi4lv1dC",
        "outputId": "9d82d845-67ec-4999-843f-13020c64bf40"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "require (n >= 0); uint y = 0; uint x = n; while (x != 0) { y++; x--; } } // test Loop invariant with do-while loop function Bar(uint n) public { require (n > 0); uint y = 0; uint x = n; do { y++; x--; } while (x != 0); } }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out)\n",
        "for row in out:\n",
        "  with open('cotract.sol', 'w') as writefile: \n",
        "    for line in row:\n",
        "       print(line)\n",
        "\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soqfnNFKPe7B",
        "outputId": "d129675c-9a02-4cba-9465-40c5561fb380"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['pragma solidity ^0.4.24; import \"./../../Libraries/VeriSolContracts.sol\"; //import \"./VeriSolContracts.sol\"; //import \"github.com/microsoft/verisol/blob/master/Libraries/VeriSolContracts.sol\"; contract LoopFor { // test Loop invariant with for loop constructor(uint n) public { require (n >= 0); uint y = 0; for (uint x = n; x!= 0; x --) { y++; } } // test Loop invariant with while loop function Foo(uint n) public { require (n >= 0); uint y = 0; for (uint x = n; x!= 0; x --) { y++; } } // test Loop invariant with while loop function whileLoop function Bar() public { require (n >= 0); uint y = 0; for (uint x = n; x!= 0; x --) { y++; } } // test Loop invariant with while loop function Foo(uint n) public { require (n >= 0); uint y<|endoftext|>\\n']]\n",
            "pragma solidity ^0.4.24; import \"./../../Libraries/VeriSolContracts.sol\"; //import \"./VeriSolContracts.sol\"; //import \"github.com/microsoft/verisol/blob/master/Libraries/VeriSolContracts.sol\"; contract LoopFor { // test Loop invariant with for loop constructor(uint n) public { require (n >= 0); uint y = 0; for (uint x = n; x!= 0; x --) { y++; } } // test Loop invariant with while loop function Foo(uint n) public { require (n >= 0); uint y = 0; for (uint x = n; x!= 0; x --) { y++; } } // test Loop invariant with while loop function whileLoop function Bar() public { require (n >= 0); uint y = 0; for (uint x = n; x!= 0; x --) { y++; } } // test Loop invariant with while loop function Foo(uint n) public { require (n >= 0); uint y<|endoftext|>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " with open('/content/LoopFor.sol', 'r') as file: \n",
        "    for line in file:\n",
        "      print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjNKKMFBn78e",
        "outputId": "3a35aead-8d22-49bf-cdd7-27094de86faa"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pragma solidity ^0.4.24;\n",
            "\n",
            "import \"./../../Libraries/VeriSolContracts.sol\";\n",
            "\n",
            "//import \"./VeriSolContracts.sol\";\n",
            "\n",
            "//import \"github.com/microsoft/verisol/blob/master/Libraries/VeriSolContracts.sol\";\n",
            "\n",
            "\n",
            "\n",
            "contract LoopFor {\n",
            "\n",
            "\n",
            "\n",
            "    // test Loop invariant with for loop\n",
            "\n",
            "    constructor(uint n) public {\n",
            "\n",
            "        require (n >= 0);\n",
            "\n",
            "        uint y = 0;\n",
            "\n",
            "        for (uint x = n; x != 0; x --) {\n",
            "\n",
            "            y++;\n",
            "\n",
            "        }\n",
            "\n",
            "    }\n",
            "\n",
            "\n",
            "\n",
            "    // test Loop invariant with while loop\n",
            "\n",
            "    function Foo(uint n) public {\n",
            "\n",
            "        require (n >= 0);\n",
            "\n",
            "        uint y = 0;\n",
            "\n",
            "        uint x = n;\n",
            "\n",
            "        while (x != 0) {\n",
            "\n",
            "            y++;\n",
            "\n",
            "            x--;\n",
            "\n",
            "        }\n",
            "\n",
            "    }\n",
            "\n",
            "\n",
            "\n",
            "    // test Loop invariant with do-while loop    \n",
            "\n",
            "    function Bar(uint n) public {\n",
            "\n",
            "        require (n > 0);\n",
            "\n",
            "        uint y = 0;\n",
            "\n",
            "        uint x = n;\n",
            "\n",
            "        do {  \n",
            "\n",
            "            y++;\n",
            "\n",
            "            x--;\n",
            "\n",
            "        } while (x != 0);\n",
            "\n",
            "    }\n",
            "\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To solve CUDA out of memory error; not necesssary here \n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='0, 1, 2, 3'\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
      ],
      "metadata": {
        "id": "BfUkAFl535nQ"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for downloading purpose \n",
        "!zip -r /content/model.zip /content/output/model_files"
      ],
      "metadata": {
        "id": "FmpWiJGphwqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7bcb79-ccf0-42aa-dffe-2381f231666f"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/output/model_files/ (stored 0%)\n",
            "updating: content/output/model_files/special_tokens_map.json (deflated 74%)\n",
            "updating: content/output/model_files/tokenizer_config.json (deflated 69%)\n",
            "updating: content/output/model_files/pytorch_model.bin (deflated 9%)\n",
            "updating: content/output/model_files/config.json (deflated 51%)\n",
            "updating: content/output/model_files/vocab.json (deflated 68%)\n",
            "updating: content/output/model_files/merges.txt (deflated 53%)\n",
            "updating: content/output/model_files/generation_config.json (deflated 24%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lPqThJg-mC1q",
        "outputId": "d17601a4-8e04-425f-995e-633af8c634ee"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_99ead138-f479-4f08-bbf8-1780b43b9a66\", \"model.zip\", 463002051)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}